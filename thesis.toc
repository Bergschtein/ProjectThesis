\babel@toc {british}{}\relax 
\contentsline {chapter}{Abstract}{v}{Doc-Start}%
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}%
\contentsline {chapter}{\numberline {2}Theoretical background}{2}{chapter.2}%
\contentsline {section}{\numberline {2.1}Neural Networks}{2}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Structure of Neural Networks}{2}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Learning in Neural Networks}{3}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}Activation Functions}{3}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}Supervised and unsupervised learning}{3}{subsection.2.1.4}%
\contentsline {section}{\numberline {2.2}Convolutional Neural Networks, CNN}{4}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Convolutional layers}{4}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}Pooling}{5}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Architecture of CNNs}{5}{subsection.2.2.3}%
\contentsline {section}{\numberline {2.3}Encoder}{6}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Downsampling blocks}{6}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Residual block}{6}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Encoder Architecture}{7}{subsection.2.3.3}%
\contentsline {section}{\numberline {2.4}Decoder}{8}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Upsampling Blocks}{8}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Decoder Architecture}{8}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Self Supervised Learning, SSL}{9}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Contrastive Learning in SSL}{9}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}Non-Contrastive Learning in SSL}{9}{subsection.2.5.2}%
\contentsline {subsection}{\numberline {2.5.3}The Role of Siamese Networks in SSL}{9}{subsection.2.5.3}%
\contentsline {subsection}{\numberline {2.5.4}Projector}{10}{subsection.2.5.4}%
\contentsline {subsubsection}{Projector architecture}{10}{section*.7}%
\contentsline {section}{\numberline {2.6}Additional Machine Learning Algorithms}{11}{section.2.6}%
\contentsline {subsection}{\numberline {2.6.1}Support Vector Machines, SVM}{11}{subsection.2.6.1}%
\contentsline {subsection}{\numberline {2.6.2}K-Neares Neighbors, KNN}{11}{subsection.2.6.2}%
\contentsline {subsection}{\numberline {2.6.3}KMeans and Silhouette Score}{12}{subsection.2.6.3}%
\contentsline {section}{\numberline {2.7}Representation Learning}{13}{section.2.7}%
\contentsline {chapter}{\numberline {3}Related work / Literature review}{14}{chapter.3}%
\contentsline {chapter}{\numberline {4}Methology}{16}{chapter.4}%
\contentsline {section}{\numberline {4.1}Overview}{16}{section.4.1}%
\contentsline {section}{\numberline {4.2}The Vector Quantized Variational Auto-Encoder, VQVAE}{16}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Evolution from Variational Auto-Encoder, VAE}{16}{subsection.4.2.1}%
\contentsline {subsubsection}{Variational inference and optimization}{17}{section*.13}%
\contentsline {subsubsection}{Challenges in Maximum Likelihood Estimation}{17}{section*.14}%
\contentsline {subsubsection}{Variational Approximation}{17}{section*.15}%
\contentsline {subsubsection}{Evidence Lower Bound}{18}{section*.16}%
\contentsline {subsection}{\numberline {4.2.2}Transition to discrete latent variables}{18}{subsection.4.2.2}%
\contentsline {subsubsection}{Vector quantization}{19}{section*.17}%
\contentsline {subsubsection}{Effect on KL divergence}{19}{section*.18}%
\contentsline {section}{\numberline {4.3}VQVAE implementation}{20}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Informational flow}{20}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Learning}{21}{subsection.4.3.2}%
\contentsline {subsubsection}{Reconstruction}{22}{section*.20}%
\contentsline {subsubsection}{Codebook-learning loss}{22}{section*.21}%
\contentsline {section}{\numberline {4.4}Modifying the VQVAE for Enhanced Self Supervised Learning}{23}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Barlow Twins}{23}{subsection.4.4.1}%
\contentsline {subsubsection}{Objective function of Barlow Twins}{23}{section*.22}%
\contentsline {subsubsection}{Siamese architecture}{24}{section*.23}%
\contentsline {subsection}{\numberline {4.4.2}Modifying the VQVAE encoder}{24}{subsection.4.4.2}%
\contentsline {subsubsection}{Learning}{25}{section*.26}%
\contentsline {subsection}{\numberline {4.4.3}Augmentation Techniques}{26}{subsection.4.4.3}%
\contentsline {chapter}{\numberline {5}Experimental Setup}{28}{chapter.5}%
\contentsline {section}{\numberline {5.1}UCR Archive}{28}{section.5.1}%
\contentsline {section}{\numberline {5.2}Reconstruction evaluation}{29}{section.5.2}%
\contentsline {section}{\numberline {5.3}Downstream evaluation}{29}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Extracting Discrete latent variables}{29}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}Downstream tests}{30}{subsection.5.3.2}%
\contentsline {chapter}{\numberline {6}Results and discussion}{31}{chapter.6}%
\contentsline {chapter}{\numberline {7}Conclusion}{32}{chapter.7}%
