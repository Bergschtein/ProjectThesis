\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@refcontext{anyt/global//global/global}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\providecommand \oddpage@label [2]{}
\babel@aux{british}{}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{Abstract}{v}{Doc-Start}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {2}Theoretical background}{2}{chapter.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{En ting å tenke på gjennom hele denne seksjonen er hvorfor du introduserer et konsept/en modell og hvem man skriver for. }{2}{section*.1}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{19562756}{33525608}
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Her snakker vi om hvorfor vi introduserer tingene vi gjør. Litt om linja vi ønsker å legge oss på, den logiske oppbygningen i seksjonen etc.}{2}{section*.2}\protected@file@percent }
\pgfsyspdfmark {pgfid2}{19562756}{30607125}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.1}Neural Networks}{2}{section.2.1}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Ikke helt fornøyd. Legge ved en kilde på hvor de ble introduser første gang. Hvem som definerte og når?}{2}{section*.3}\protected@file@percent }
\pgfsyspdfmark {pgfid3}{19562756}{19552222}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Structure of Neural Networks}{2}{subsection.2.1.1}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Her må det komme en definisjon. Matriseformen er fin. Finn en god kilde på det.}{2}{section*.4}\protected@file@percent }
\pgfsyspdfmark {pgfid4}{19562756}{13965812}
\abx@aux@cite{ReLuGrad}
\abx@aux@segm{0}{0}{ReLuGrad}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Simple neural network consisting of a single hidden layer.\relax }}{3}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Learning in Neural Networks}{3}{subsection.2.1.2}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Her vil jeg egentlig at du tydelig snakker om gradient descent, og varianter av algoritmen. Referer til en kilde som går gjennom gradient descent i detalj}{3}{section*.6}\protected@file@percent }
\pgfsyspdfmark {pgfid5}{19562756}{29036277}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Activation Functions}{3}{subsection.2.1.3}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Her bør det refereres til definisjonen av et NN. Nevne hvorfor det er rimelig at NN med ikke-lineær aktiveringsfunksjon kan approksimere mange ting: http://www.vision.jhu.edu/teaching/learning/deeplearning18/assets/Cybenko-89.pdf}{3}{section*.7}\protected@file@percent }
\pgfsyspdfmark {pgfid6}{19562756}{19211758}
\abx@aux@cite{CNNs}
\abx@aux@segm{0}{0}{CNNs}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Supervised and unsupervised learning}{4}{subsection.2.1.4}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Heller start med "In machine learning"??}{4}{section*.8}\protected@file@percent }
\pgfsyspdfmark {pgfid7}{13091697}{43755243}
\pgfsyspdfmark {pgfid10}{36067557}{43757755}
\pgfsyspdfmark {pgfid11}{38009087}{43524350}
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Klassifisering er jo ikke supervised eller unsupervised? Definer klart hva supervised er, og så hva unsupervised er. Så kom med et klart eksempel på hver. Snakk også gjerne om hvor mye mer utbredt supervised er enn unsupervised.}{4}{section*.9}\protected@file@percent }
\pgfsyspdfmark {pgfid12}{19562756}{36787313}
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Loss function? dette er første gang det nevnes. Definitivt verdt å definere sammen med "learning"}{4}{section*.10}\protected@file@percent }
\pgfsyspdfmark {pgfid13}{19562756}{30776321}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.2}Convolutional Neural Networks, CNN}{4}{section.2.2}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Dette avsnittet er en direkte kopi fra https://www.deeplearningbook.org/contents/convnets.html}{4}{section*.11}\protected@file@percent }
\pgfsyspdfmark {pgfid14}{19562756}{24036425}
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{riktig kilde?}{4}{section*.12}\protected@file@percent }
\pgfsyspdfmark {pgfid15}{19895583}{21613080}
\pgfsyspdfmark {pgfid18}{36067557}{21615592}
\pgfsyspdfmark {pgfid19}{38009087}{21382187}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Convolutional layers}{4}{subsection.2.2.1}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Ville skrevet mer i symboler her. Matematisk definert diskret konvulosjon? Lettere å snakke om K som en kjerne da.}{4}{section*.13}\protected@file@percent }
\pgfsyspdfmark {pgfid20}{19562756}{13579798}
\abx@aux@cite{RiebesellTikZ2022}
\abx@aux@segm{0}{0}{RiebesellTikZ2022}
\abx@aux@cite{RiebesellTikZ2022}
\abx@aux@segm{0}{0}{RiebesellTikZ2022}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Example of convolutional operation. $\mathbf  {I}$ is the input, $\mathbf  {K}$ is the kernel and $\mathbf  {I} * \mathbf  {K}$ is the activation map. Illustration taken from the Random TikZ collection\cite {RiebesellTikZ2022}\relax }}{5}{figure.caption.14}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Pooling}{5}{subsection.2.2.2}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Downsampling is a good word.}{5}{section*.15}\protected@file@percent }
\pgfsyspdfmark {pgfid22}{19562756}{17180290}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Illustration of a max pooling operation. The input feature map is reduced in size by applying a max pooling filter with size 2x2 (red boxes), which selects the maximum value in each filter region to produce the max pooled feature map.\relax }}{6}{figure.caption.16}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Architecture of CNNs}{6}{subsection.2.2.3}\protected@file@percent }
\abx@aux@cite{batchnorm}
\abx@aux@segm{0}{0}{batchnorm}
\abx@aux@cite{ResLearn}
\abx@aux@segm{0}{0}{ResLearn}
\abx@aux@cite{ResLearn}
\abx@aux@segm{0}{0}{ResLearn}
\abx@aux@cite{ResLearn}
\abx@aux@segm{0}{0}{ResLearn}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.3}Encoder}{7}{section.2.3}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Her ville jeg flyttet hele Encoder/Decoder og Projector delen til Methodology, og heller laget en seksjon her med Residual Networks som du kan referere til når du introduserer Encoder og Decoder i VQVAE sammenheng.}{7}{section*.17}\protected@file@percent }
\pgfsyspdfmark {pgfid24}{19562756}{46120452}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Downsampling blocks}{7}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Residual block}{7}{subsection.2.3.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Illustration of the Resnet block from He et al's original paper\cite {ResLearn} \relax }}{8}{figure.caption.18}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Encoder Architecture}{8}{subsection.2.3.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Illustration of the Encoder architecture used in the VQVAE implementation. The first downsample block reduces the dimensionality, followed by further downsample blocks to capture important features.\relax }}{8}{figure.caption.19}\protected@file@percent }
\abx@aux@cite{MoCo}
\abx@aux@segm{0}{0}{MoCo}
\abx@aux@cite{SimCLR}
\abx@aux@segm{0}{0}{SimCLR}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.4}Decoder}{9}{section.2.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Upsampling Blocks}{9}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Decoder Architecture}{9}{subsection.2.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.5}Self Supervised Learning, SSL}{9}{section.2.5}\protected@file@percent }
\abx@aux@cite{BYOL}
\abx@aux@segm{0}{0}{BYOL}
\abx@aux@cite{Barlow}
\abx@aux@segm{0}{0}{Barlow}
\abx@aux@cite{Siamese}
\abx@aux@segm{0}{0}{Siamese}
\abx@aux@cite{SSLs}
\abx@aux@segm{0}{0}{SSLs}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Contrastive Learning in SSL}{10}{subsection.2.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Non-Contrastive Learning in SSL}{10}{subsection.2.5.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}The Role of Siamese Networks in SSL}{10}{subsection.2.5.3}\protected@file@percent }
\abx@aux@cite{svm}
\abx@aux@segm{0}{0}{svm}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces  Example of a non contrastive siamese network using augmented views. Here the images are processed to calculate a similarity score, the backpropagation arrow indicates that the similarity score is then used to update the weights of the sub network. Pictures taken from \url  {www.pexels.com}\relax }}{11}{figure.caption.20}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Projector}{11}{subsection.2.5.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Projector architecture}{11}{section*.21}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Bit vague}{11}{section*.22}\protected@file@percent }
\pgfsyspdfmark {pgfid25}{9791217}{24799079}
\pgfsyspdfmark {pgfid28}{36067557}{24801591}
\pgfsyspdfmark {pgfid29}{38009087}{24568186}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.6}Additional Machine Learning Algorithms}{11}{section.2.6}\protected@file@percent }
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{Jeg er strengt tatt ikke sikker på om du trenger å ha med dette. SVM, KNN og KMeans er jo kjent fra bachelornivå. Vi skal skrive for en mastersudent i stat/ML}{11}{section*.23}\protected@file@percent }
\pgfsyspdfmark {pgfid30}{19562756}{12555104}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Support Vector Machines, SVM}{12}{subsection.2.6.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Vizualisation of the hyperplane, margin and support vectors in a SVM procedure.\relax }}{12}{figure.caption.24}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}K-Neares Neighbors, KNN}{12}{subsection.2.6.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Classification of middle point in a KNN procedure. For $k=2$ the majority vote is purple while for $k=5$ it is blue.\relax }}{13}{figure.caption.25}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:knn}{{2.8}{13}{Classification of middle point in a KNN procedure. For $k=2$ the majority vote is purple while for $k=5$ it is blue.\relax }{figure.caption.25}{}}
\newlabel{fig:knn@cref}{{[figure][8][2]2.8}{[1][12][]13}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}KMeans and Silhouette Score}{13}{subsection.2.6.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Illustration of the silhuette score metric applied. On the left we see well seperated clusters with a silhouette score equal to 1. On the right a not so well seperation, giving a silhouette score less than 1.\relax }}{14}{figure.caption.26}\protected@file@percent }
\newlabel{fig:knn}{{2.9}{14}{Illustration of the silhuette score metric applied. On the left we see well seperated clusters with a silhouette score equal to 1. On the right a not so well seperation, giving a silhouette score less than 1.\relax }{figure.caption.26}{}}
\newlabel{fig:knn@cref}{{[figure][9][2]2.9}{[1][13][]14}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2.7}Representation Learning}{14}{section.2.7}\protected@file@percent }
\abx@aux@cite{neuvqvae}
\abx@aux@segm{0}{0}{neuvqvae}
\abx@aux@cite{VQVAE-2}
\abx@aux@segm{0}{0}{VQVAE-2}
\abx@aux@cite{lee2023masked}
\abx@aux@segm{0}{0}{lee2023masked}
\abx@aux@cite{cvae}
\abx@aux@segm{0}{0}{cvae}
\abx@aux@cite{Barlow}
\abx@aux@segm{0}{0}{Barlow}
\abx@aux@cite{SSLs}
\abx@aux@segm{0}{0}{SSLs}
\abx@aux@cite{UCRArchive2018}
\abx@aux@segm{0}{0}{UCRArchive2018}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {3}Related work / Literature review}{15}{chapter.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{tdo}{\defcounter {refsection}{0}\relax }\@writefile{tdo}{\contentsline {todo}{fill}{15}{section*.27}\protected@file@percent }
\pgfsyspdfmark {pgfid31}{9382893}{21364465}
\pgfsyspdfmark {pgfid34}{36067557}{21366977}
\pgfsyspdfmark {pgfid35}{38009087}{21133572}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {4}Methology}{17}{chapter.4}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.1}Overview}{17}{section.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.2}The Vector Quantized Variational Auto-Encoder, VQVAE}{17}{section.4.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}Evolution from Variational Auto-Encoder, VAE}{17}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Variational inference and optimization}{18}{section*.28}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Challenges in Maximum Likelihood Estimation}{18}{section*.29}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Variational Approximation}{18}{section*.30}\protected@file@percent }
\abx@aux@cite{VAE}
\abx@aux@segm{0}{0}{VAE}
\abx@aux@cite{1312.6114}
\abx@aux@segm{0}{0}{1312.6114}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Evidence Lower Bound}{19}{section*.31}\protected@file@percent }
\newlabel{eq:ELBO}{{4.5}{19}{Evidence Lower Bound}{equation.4.5}{}}
\newlabel{eq:ELBO@cref}{{[equation][5][4]4.5}{[1][19][]19}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Transition to discrete latent variables}{19}{subsection.4.2.2}\protected@file@percent }
\abx@aux@cite{neuvqvae}
\abx@aux@segm{0}{0}{neuvqvae}
\abx@aux@cite{neuvqvae}
\abx@aux@segm{0}{0}{neuvqvae}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Vector quantization}{20}{section*.32}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Effect on KL divergence}{20}{section*.33}\protected@file@percent }
\abx@aux@cite{posteriorcollapse}
\abx@aux@segm{0}{0}{posteriorcollapse}
\abx@aux@cite{lee2023masked}
\abx@aux@segm{0}{0}{lee2023masked}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.3}VQVAE implementation}{21}{section.4.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Informational flow}{21}{subsection.4.3.1}\protected@file@percent }
\abx@aux@cite{lee2023masked}
\abx@aux@segm{0}{0}{lee2023masked}
\abx@aux@cite{lee2023masked}
\abx@aux@segm{0}{0}{lee2023masked}
\abx@aux@cite{lee2023masked}
\abx@aux@segm{0}{0}{lee2023masked}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces  Illustration of the VQVAE. Illustration and implementation inspired by the TimeVQVAE paper\cite {lee2023masked} \relax }}{22}{figure.caption.34}\protected@file@percent }
\newlabel{fig:VQVAE}{{4.1}{22}{Illustration of the VQVAE. Illustration and implementation inspired by the TimeVQVAE paper\cite {lee2023masked} \relax }{figure.caption.34}{}}
\newlabel{fig:VQVAE@cref}{{[figure][1][4]4.1}{[1][22][]22}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Learning}{22}{subsection.4.3.2}\protected@file@percent }
\newlabel{eq:VQVAEloss}{{4.9}{22}{Learning}{equation.4.9}{}}
\newlabel{eq:VQVAEloss@cref}{{[equation][9][4]4.9}{[1][22][]22}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Reconstruction}{23}{section*.35}\protected@file@percent }
\newlabel{eq:recon}{{4.12}{23}{Reconstruction}{equation.4.12}{}}
\newlabel{eq:recon@cref}{{[equation][12][4]4.12}{[1][23][]23}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Codebook-learning loss}{23}{section*.36}\protected@file@percent }
\abx@aux@cite{Barlow}
\abx@aux@segm{0}{0}{Barlow}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4.4}Modifying the VQVAE for Enhanced Self Supervised Learning}{24}{section.4.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Barlow Twins}{24}{subsection.4.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Objective function of Barlow Twins}{24}{section*.37}\protected@file@percent }
\abx@aux@cite{Barlow}
\abx@aux@segm{0}{0}{Barlow}
\abx@aux@cite{Barlow}
\abx@aux@segm{0}{0}{Barlow}
\abx@aux@cite{Barlow}
\abx@aux@segm{0}{0}{Barlow}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Siamese architecture}{25}{section*.38}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Illustration of the Barlow Twins procedure, inspired by the original paper\cite {Barlow}.\relax }}{25}{figure.caption.39}\protected@file@percent }
\newlabel{fig:Barlow}{{4.2}{25}{Illustration of the Barlow Twins procedure, inspired by the original paper\cite {Barlow}.\relax }{figure.caption.39}{}}
\newlabel{fig:Barlow@cref}{{[figure][2][4]4.2}{[1][25][]25}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Modifying the VQVAE encoder}{25}{subsection.4.4.2}\protected@file@percent }
\abx@aux@cite{VICReg}
\abx@aux@segm{0}{0}{VICReg}
\abx@aux@cite{Barlow}
\abx@aux@segm{0}{0}{Barlow}
\abx@aux@cite{SSLs}
\abx@aux@segm{0}{0}{SSLs}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Illustration of the Barlow Twins modification to VQVAE including the loss function calculation.\relax }}{26}{figure.caption.40}\protected@file@percent }
\newlabel{fig:BTVQVAE}{{4.3}{26}{Illustration of the Barlow Twins modification to VQVAE including the loss function calculation.\relax }{figure.caption.40}{}}
\newlabel{fig:BTVQVAE@cref}{{[figure][3][4]4.3}{[1][26][]26}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsubsection}{Learning}{26}{section*.41}\protected@file@percent }
\abx@aux@cite{augs}
\abx@aux@segm{0}{0}{augs}
\abx@aux@cite{SSLs}
\abx@aux@segm{0}{0}{SSLs}
\newlabel{eq:BTVQVAEloss}{{4.18}{27}{Learning}{equation.4.18}{}}
\newlabel{eq:BTVQVAEloss@cref}{{[equation][18][4]4.18}{[1][27][]27}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Augmentation Techniques}{27}{subsection.4.4.3}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Visualization of the flip, slope and STFT augmentation aplied on a timeseries. \relax }}{28}{figure.caption.44}\protected@file@percent }
\abx@aux@cite{UCRArchive2018}
\abx@aux@segm{0}{0}{UCRArchive2018}
\abx@aux@cite{SSLs}
\abx@aux@segm{0}{0}{SSLs}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experimental Setup}{29}{chapter.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.1}UCR Archive}{29}{section.5.1}\protected@file@percent }
\abx@aux@cite{SSLs}
\abx@aux@segm{0}{0}{SSLs}
\abx@aux@cite{SSLs}
\abx@aux@segm{0}{0}{SSLs}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Chosen UCR Archive subset. Data collected by Lee et al\cite {SSLs}\relax }}{30}{table.caption.45}\protected@file@percent }
\newlabel{tab:sample_table}{{5.1}{30}{Chosen UCR Archive subset. Data collected by Lee et al\cite {SSLs}\relax }{table.caption.45}{}}
\newlabel{tab:sample_table@cref}{{[table][1][5]5.1}{[1][30][]30}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.2}Reconstruction evaluation}{30}{section.5.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5.3}Downstream evaluation}{30}{section.5.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Extracting Discrete latent variables}{30}{subsection.5.3.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Illustration showing the processing of training and validation datasets to latent representations.\relax }}{31}{figure.caption.46}\protected@file@percent }
\newlabel{fig:latents}{{5.1}{31}{Illustration showing the processing of training and validation datasets to latent representations.\relax }{figure.caption.46}{}}
\newlabel{fig:latents@cref}{{[figure][1][5]5.1}{[1][31][]31}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Downstream tests}{31}{subsection.5.3.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {6}Results and discussion}{32}{chapter.6}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {chapter}{\numberline {7}Conclusion}{33}{chapter.7}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\addvspace {10\p@ }}
\abx@aux@read@bbl@mdfivesum{9015A606DFA929316CF04592E7A4208C}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{cvae}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{VICReg}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{SimCLR}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{svm}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{UCRArchive2018}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{BYOL}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{ResLearn}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{MoCo}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{batchnorm}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{1312.6114}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{VAE}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{SSLs}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{lee2023masked}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Siamese}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{CNNs}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{neuvqvae}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{RiebesellTikZ2022}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{VQVAE-2}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{ReLuGrad}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{posteriorcollapse}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{augs}{anyt/global//global/global}
\abx@aux@defaultrefcontext{0}{Barlow}{anyt/global//global/global}
\gdef \@abspage@last{42}
